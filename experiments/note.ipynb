{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<font size=\"7\">Image Search</font>\n",
    "</div>\n",
    "\n",
    "<br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import json\n",
    "import pickle\n",
    "import chainer\n",
    "from chainer import Variable, Chain\n",
    "from chainer import links as L, functions as F\n",
    "from chainer import optimizers, serializers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display\n",
    "\n",
    "from VariableLengthUtils.RNN import BLSTM, LSTM\n",
    "from VariableLengthUtils.EmbedID import EmbedID\n",
    "from VariableLengthUtils.functions import batchsort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw dataset\n",
    "- Download datasets from here: http://cs.stanford.edu/people/karpathy/deepimagesent/\n",
    "- Extract the downloaded file to ../data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datafile = 'data/flickr8k/dataset.json'\n",
    "\n",
    "with open(datafile, 'r') as f:\n",
    "    datas = json.load(f)['images']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess\n",
    "- convert token into ID\n",
    "- length of idset array is 8000 * 5 = 40000\n",
    "- captions of a image data with $imgid$ are $idset\\left[imgid * 5:imgid * 5 + 5\\right]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idset = []\n",
    "wd2id = {'<bos>': 0,\n",
    "         '<eos>': 1,\n",
    "         '<unk>': 2,}\n",
    "count = {}\n",
    "\n",
    "max_wd_count = 5 # if #occurrences of a token is less than it,\n",
    "                 #              convert the token into <unk>.\n",
    "\n",
    "for data in datas:\n",
    "    for sentence in data['sentences']:\n",
    "        for wd in sentence['tokens']:\n",
    "            if wd not in count:\n",
    "                count[wd] = 0\n",
    "            count[wd] += 1\n",
    "\n",
    "for data in datas:\n",
    "    for sentence in data['sentences']:\n",
    "        sid = []\n",
    "        for wd in sentence['tokens']:\n",
    "            if count[wd] < max_wd_count:\n",
    "                sid.append(wd2id['<unk>'])\n",
    "            else:\n",
    "                if wd not in wd2id:\n",
    "                    wd2id[wd] = len(wd2id)\n",
    "                sid.append(wd2id[wd])\n",
    "        idset.append(sid)\n",
    "\n",
    "idset = [np.asarray(x_, dtype=np.int32) for x_ in idset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save converted dataset\n",
    "idfile = 'data/flickr8k/idset.pkl'\n",
    "wd2idfile = 'data/flickr8k/wd2id.pkl'\n",
    "with open(idfile, 'wb') as f:\n",
    "    pickle.dump(idset, f)\n",
    "\n",
    "with open(wd2idfile, 'wb') as f:\n",
    "    pickle.dump(wd2id, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "- Load preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idfile = 'data/flickr8k/idset.pkl'\n",
    "wd2idfile = 'data/flickr8k/wd2id.pkl'\n",
    "featfile = 'data/flickr8k/vgg_feats.mat'\n",
    "\n",
    "with open(idfile, 'rb') as f:\n",
    "    idset = pickle.load(f)\n",
    "\n",
    "with open(wd2idfile, 'rb') as f:\n",
    "    wd2id = pickle.load(f)\n",
    "\n",
    "feats_ = scipy.io.loadmat(featfile)['feats'].T\n",
    "feats = feats_.repeat(5, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "- Embed sentence into the same feature space as image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSTMEmbed(Chain):\n",
    "    def __init__(self, in_size, out_size, train=True):\n",
    "        super().__init__(\n",
    "            embed=L.EmbedID(in_size, 512),\n",
    "            lstm=L.LSTM(512, 512),\n",
    "            out=L.Linear(512, out_size)\n",
    "        )\n",
    "        self.train = train\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        x = F.transpose_sequence(x)\n",
    "        for x_ in x:\n",
    "            self.lstm(F.dropout(self.embed(x_), train=self.train))\n",
    "        h = self.out(F.dropout(self.lstm.h, train=self.train))\n",
    "        return h\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.lstm.reset_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 4096)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgembed = LSTMEmbed(len(wd2id), feats.shape[1])\n",
    "x = batchsort(idset)[:20]\n",
    "y = imgembed(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiLSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ImgEmbed(Chain):\n",
    "    def __init__(self, in_size, out_size, train=True):\n",
    "        super().__init__(\n",
    "            embed = EmbedID(in_size, 512),\n",
    "            blstm = BLSTM(512, 512),\n",
    "            lstm  = LSTM(512, 1024),\n",
    "            out   = L.Linear(1024, out_size)\n",
    "        )\n",
    "        self.train = train\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        h = self.embed(x, dropout=self.train)\n",
    "        h = self.blstm(h)\n",
    "        h= self.lstm(h)\n",
    "        h = self.out(F.dropout(h, train=self.train))\n",
    "        return h\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.blstm.reset_state()\n",
    "        self.lstm.reset_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 4096)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgembed = ImgEmbed(len(wd2id), feats.shape[1])\n",
    "x = batchsort(idset)[:20]\n",
    "y = imgembed(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_data = len(idset)\n",
    "n_vocab = len(wd2id)\n",
    "\n",
    "n_epochs = 200\n",
    "batchsize = 100\n",
    "\n",
    "save_cycle = 20\n",
    "save_dir = './model/lstmembed_4096'\n",
    "model_name = 'model_{}epoch.npz'\n",
    "optim_name = 'optim_{}epoch.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = LSTMEmbed(n_vocab, feats.shape[1])\n",
    "\n",
    "optimizer = optimizers.Adam()\n",
    "optimizer.setup(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: loss = 1.05745267868042\n",
      "epoch 2: loss = 1.0224376916885376\n",
      "epoch 3: loss = 1.0450522899627686\n",
      "epoch 4: loss = 1.0502630472183228\n",
      "epoch 5: loss = 0.9869892597198486\n",
      "epoch 6: loss = 0.9716061949729919\n",
      "epoch 7: loss = 0.9330874085426331\n",
      "epoch 8: loss = 0.9541282057762146\n",
      "epoch 9: loss = 0.9190133810043335\n",
      "epoch 10: loss = 0.9376640319824219\n",
      "epoch 11: loss = 0.9843006134033203\n",
      "epoch 12: loss = 1.004133939743042\n",
      "epoch 13: loss = 0.9328920841217041\n",
      "epoch 14: loss = 0.9882013201713562\n",
      "epoch 15: loss = 0.9031590223312378\n",
      "epoch 16: loss = 0.9104897975921631\n",
      "epoch 17: loss = 0.9436786770820618\n",
      "epoch 18: loss = 0.8794094324111938\n",
      "epoch 19: loss = 0.9833486676216125\n",
      "epoch 20: loss = 0.9442304968833923\n",
      "save model and optimizer: ./model/lstmembed_4096model_20epoch.npz, ./model/lstmembed_4096optim_20epoch.npz\n",
      "epoch 21: loss = 0.9449388384819031\n",
      "epoch 22: loss = 0.9603814482688904\n",
      "epoch 23: loss = 0.8824542760848999\n",
      "epoch 24: loss = 0.9276063442230225\n",
      "epoch 25: loss = 0.8549638390541077\n",
      "epoch 26: loss = 0.910157322883606\n",
      "epoch 27: loss = 0.8401604294776917\n",
      "epoch 28: loss = 0.9415046572685242\n",
      "epoch 29: loss = 0.9226863384246826\n",
      "epoch 30: loss = 0.9018661975860596\n",
      "epoch 31: loss = 0.9127453565597534\n",
      "epoch 32: loss = 0.930210292339325\n",
      "epoch 33: loss = 0.9401302933692932\n",
      "epoch 34: loss = 0.8972790241241455\n",
      "epoch 35: loss = 0.879225492477417\n",
      "epoch 36: loss = 0.9554954767227173\n",
      "epoch 37: loss = 0.9175354242324829\n",
      "epoch 38: loss = 0.9064090847969055\n",
      "epoch 39: loss = 0.8681957721710205\n",
      "epoch 40: loss = 0.9106423258781433\n",
      "save model and optimizer: ./model/lstmembed_4096model_40epoch.npz, ./model/lstmembed_4096optim_40epoch.npz\n",
      "epoch 41: loss = 0.8663493394851685\n",
      "epoch 42: loss = 0.9015055894851685\n",
      "epoch 43: loss = 0.9081671237945557\n",
      "epoch 44: loss = 0.8764761090278625\n",
      "epoch 45: loss = 0.8719141483306885\n",
      "epoch 46: loss = 0.8902848958969116\n",
      "epoch 47: loss = 0.8869184851646423\n",
      "epoch 48: loss = 0.8763455152511597\n",
      "epoch 49: loss = 0.8529303669929504\n",
      "epoch 50: loss = 0.9042905569076538\n",
      "epoch 51: loss = 0.8542109727859497\n",
      "epoch 52: loss = 0.9420920014381409\n",
      "epoch 53: loss = 0.8582442998886108\n",
      "epoch 54: loss = 0.9092172980308533\n",
      "epoch 55: loss = 0.9554873108863831\n",
      "epoch 56: loss = 0.8461298942565918\n",
      "epoch 57: loss = 0.8955422043800354\n",
      "epoch 58: loss = 0.879911482334137\n",
      "epoch 59: loss = 0.8509719371795654\n",
      "epoch 60: loss = 0.8948214650154114\n",
      "save model and optimizer: ./model/lstmembed_4096model_60epoch.npz, ./model/lstmembed_4096optim_60epoch.npz\n",
      "epoch 61: loss = 0.834658145904541\n",
      "epoch 62: loss = 0.8831868767738342\n",
      "epoch 63: loss = 0.9038601517677307\n",
      "epoch 64: loss = 0.8825930953025818\n",
      "epoch 65: loss = 0.9120773077011108\n",
      "epoch 66: loss = 0.932533860206604\n",
      "epoch 67: loss = 0.9117560386657715\n",
      "epoch 68: loss = 0.9371777176856995\n",
      "epoch 69: loss = 0.887125551700592\n",
      "epoch 70: loss = 0.8663633465766907\n",
      "epoch 71: loss = 0.8530285358428955\n",
      "epoch 72: loss = 0.854083240032196\n",
      "epoch 73: loss = 0.8699300289154053\n",
      "epoch 74: loss = 0.8818994164466858\n",
      "epoch 75: loss = 0.8916366100311279\n",
      "epoch 76: loss = 0.8831716775894165\n",
      "epoch 77: loss = 0.8864238262176514\n",
      "epoch 78: loss = 0.897818922996521\n",
      "epoch 79: loss = 0.836716890335083\n",
      "epoch 80: loss = 0.8938852548599243\n",
      "save model and optimizer: ./model/lstmembed_4096model_80epoch.npz, ./model/lstmembed_4096optim_80epoch.npz\n",
      "epoch 81: loss = 0.8906568288803101\n",
      "epoch 82: loss = 0.859404444694519\n",
      "epoch 83: loss = 0.8779836893081665\n",
      "epoch 84: loss = 0.9011788368225098\n",
      "epoch 85: loss = 0.8823486566543579\n",
      "epoch 86: loss = 0.8231448531150818\n",
      "epoch 87: loss = 0.8516406416893005\n",
      "epoch 88: loss = 0.8550471663475037\n",
      "epoch 89: loss = 0.8377179503440857\n",
      "epoch 90: loss = 0.925771951675415\n",
      "epoch 91: loss = 0.8562597632408142\n",
      "epoch 92: loss = 0.8712000250816345\n",
      "epoch 93: loss = 0.8768215179443359\n",
      "epoch 94: loss = 0.8568667769432068\n",
      "epoch 95: loss = 0.8439235091209412\n",
      "epoch 96: loss = 0.8832260370254517\n",
      "epoch 97: loss = 0.8333010673522949\n",
      "epoch 98: loss = 0.8327341675758362\n",
      "epoch 99: loss = 0.8512321710586548\n",
      "epoch 100: loss = 0.8501666188240051\n",
      "save model and optimizer: ./model/lstmembed_4096model_100epoch.npz, ./model/lstmembed_4096optim_100epoch.npz\n",
      "epoch 101: loss = 0.8205353021621704\n",
      "epoch 102: loss = 0.9052215814590454\n",
      "epoch 103: loss = 0.8819341063499451\n",
      "epoch 104: loss = 0.8238359093666077\n",
      "epoch 105: loss = 0.8914127945899963\n",
      "epoch 106: loss = 0.8102476596832275\n",
      "epoch 107: loss = 0.8606783151626587\n",
      "epoch 108: loss = 0.8848544955253601\n",
      "epoch 109: loss = 0.8508115410804749\n",
      "epoch 110: loss = 0.8219041228294373\n",
      "epoch 111: loss = 0.8207758069038391\n",
      "epoch 112: loss = 0.8871403336524963\n",
      "epoch 113: loss = 0.846904456615448\n",
      "epoch 114: loss = 0.8213819265365601\n",
      "epoch 115: loss = 0.8417928218841553\n",
      "epoch 116: loss = 0.854230523109436\n",
      "epoch 117: loss = 0.8535377383232117\n",
      "epoch 118: loss = 0.8889399170875549\n",
      "epoch 119: loss = 0.8961206078529358\n",
      "epoch 120: loss = 0.896186113357544\n",
      "save model and optimizer: ./model/lstmembed_4096model_120epoch.npz, ./model/lstmembed_4096optim_120epoch.npz\n",
      "epoch 121: loss = 0.8255100846290588\n",
      "epoch 122: loss = 0.8631698489189148\n",
      "epoch 123: loss = 0.8037741780281067\n",
      "epoch 124: loss = 0.8496730923652649\n",
      "epoch 125: loss = 0.8380878567695618\n",
      "epoch 126: loss = 0.7926977276802063\n",
      "epoch 127: loss = 0.8572050333023071\n",
      "epoch 128: loss = 0.8122131824493408\n",
      "epoch 129: loss = 0.8534718155860901\n",
      "epoch 130: loss = 0.8295732736587524\n",
      "epoch 131: loss = 0.8909835815429688\n",
      "epoch 132: loss = 0.8607824444770813\n",
      "epoch 133: loss = 0.8024955987930298\n",
      "epoch 134: loss = 0.8714247941970825\n",
      "epoch 135: loss = 0.8653761148452759\n",
      "epoch 136: loss = 0.8590958118438721\n",
      "epoch 137: loss = 0.8741341233253479\n",
      "epoch 138: loss = 0.872151255607605\n",
      "epoch 139: loss = 0.8649746179580688\n",
      "epoch 140: loss = 0.8278487920761108\n",
      "save model and optimizer: ./model/lstmembed_4096model_140epoch.npz, ./model/lstmembed_4096optim_140epoch.npz\n",
      "epoch 141: loss = 0.8682284355163574\n",
      "epoch 142: loss = 0.8388367295265198\n",
      "epoch 143: loss = 0.8694571852684021\n",
      "epoch 144: loss = 0.8661242723464966\n",
      "epoch 145: loss = 0.873826801776886\n",
      "epoch 146: loss = 0.8578050136566162\n",
      "epoch 147: loss = 0.8714956045150757\n",
      "epoch 148: loss = 0.7811447381973267\n",
      "epoch 149: loss = 0.851574182510376\n",
      "epoch 150: loss = 0.8395366072654724\n",
      "epoch 151: loss = 0.8300533890724182\n",
      "epoch 152: loss = 0.8795498013496399\n",
      "epoch 153: loss = 0.8286876678466797\n",
      "epoch 154: loss = 0.8124926686286926\n",
      "epoch 155: loss = 0.8394322991371155\n",
      "epoch 156: loss = 0.8466914892196655\n",
      "epoch 157: loss = 0.8892788887023926\n",
      "epoch 158: loss = 0.8238939046859741\n",
      "epoch 159: loss = 0.83935546875\n",
      "epoch 160: loss = 0.8071231245994568\n",
      "save model and optimizer: ./model/lstmembed_4096model_160epoch.npz, ./model/lstmembed_4096optim_160epoch.npz\n",
      "epoch 161: loss = 0.8488487005233765\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-1a93b4cf604c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcleargrads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-e9fd4058c203>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/altescy/.pyenv/versions/anaconda3-4.3.0/lib/python3.6/site-packages/chainer/links/connection/lstm.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    248\u001b[0m                     \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                     volatile='auto')\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mh_rest\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/altescy/.pyenv/versions/anaconda3-4.3.0/lib/python3.6/site-packages/chainer/functions/activation/lstm.py\u001b[0m in \u001b[0;36mlstm\u001b[0;34m(c_prev, x)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \"\"\"\n\u001b[0;32m--> 228\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/altescy/.pyenv/versions/anaconda3-4.3.0/lib/python3.6/site-packages/chainer/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# Forward prop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0min_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitervalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/altescy/.pyenv/versions/anaconda3-4.3.0/lib/python3.6/site-packages/chainer/functions/activation/lstm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mc_next\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_prev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/altescy/.pyenv/versions/anaconda3-4.3.0/lib/python3.6/site-packages/chainer/functions/activation/lstm.py\u001b[0m in \u001b[0;36m_sigmoid\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_sigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mhalf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mhalf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mhalf\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhalf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pb = FloatProgress(min=0, max=(n_data//batchsize)*n_epochs)\n",
    "display(pb)\n",
    "\n",
    "errors = []\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    shuffle_idx = np.random.permutation(np.arange(n_data))\n",
    "    for i in range(0, n_data, batchsize):\n",
    "        batch_idx = shuffle_idx[i:i+batchsize if i+batchsize < n_data else n_data]\n",
    "        x_batch = [idset[idx] for idx in batch_idx]\n",
    "        y_batch = feats[batch_idx]\n",
    "        x_batch, y_batch = batchsort(x_batch, y_batch)\n",
    "        \n",
    "        model.reset_state()\n",
    "        loss = F.mean_squared_error(model(x_batch), y_batch)\n",
    "        \n",
    "        model.cleargrads()\n",
    "        loss.backward()\n",
    "        optimizer.update()\n",
    "        \n",
    "        errors.append(loss.data)\n",
    "        pb.value += 1\n",
    "        \n",
    "    print(\"epoch {}: loss = {}\".format(epoch, loss.data))\n",
    "    \n",
    "    if epoch % save_cycle == 0:\n",
    "        model_fp = os.path.join(save_dir, model_name.format(epoch))\n",
    "        optim_fp = os.path.join(save_dir, optim_name.format(epoch))\n",
    "        serializers.save_npz(model_fp, model)\n",
    "        serializers.save_npz(optim_fp, optimizer)\n",
    "        print('save model and optimizer: {}, {}'.format(model_fp, optim_fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7977079da0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npeAXlfbeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f79773d4a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Older-Embeddings of images and language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AbsLSTMEmbed(Chain):\n",
    "    def __init__(self, in_size, out_size, train=True):\n",
    "        super().__init__(\n",
    "            embed=L.EmbedID(in_size, 300),\n",
    "            lstm=L.LSTM(300, 300),\n",
    "            out=L.Linear(300, out_size)\n",
    "        )\n",
    "        self.train = train\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        x = F.transpose_sequence(x)\n",
    "        for x_ in x:\n",
    "            self.lstm(F.dropout(self.embed(x_), train=self.train))\n",
    "        h = self.out(F.dropout(self.lstm.h, train=self.train))\n",
    "        return F.absolute(h)\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.lstm.reset_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CNNOut(Chain):\n",
    "    def __init__(self, in_size, out_size):\n",
    "        super().__init__(\n",
    "            linear=L.Linear(in_size, out_size)\n",
    "        )\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return F.absolute(self.linear(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score(x, y):\n",
    "    return -F.batch_l2_norm_squared(F.relu(y - x))\n",
    "\n",
    "def lossfun(c, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimension reduction using DAE\n",
    "- Reduce #dimensions of feature space using Denoising Autoencoder(DAE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DAE(Chain):\n",
    "    def __init__(self, in_size, mid_size):\n",
    "        super().__init__(\n",
    "            encoder=L.Linear(in_size, mid_size),\n",
    "            decoder=L.Linear(mid_size, in_size)\n",
    "        )\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        # add gaussian noise\n",
    "        eps = np.random.randn(x.size).reshape(x.shape)\n",
    "        x += eps\n",
    "        \n",
    "        h = F.sigmoid(self.encoder(x))\n",
    "        h = self.decoder(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4096)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dae = DAE(feats.shape[1], 512)\n",
    "y = dae(feats[:2])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train DAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_feats, in_size = feats_.shape\n",
    "mid_size = 512\n",
    "\n",
    "n_epochs = 200\n",
    "batchsize = 100\n",
    "\n",
    "save_cycle = 10\n",
    "save_dir = './model/dae_512/'\n",
    "model_name = 'dae_{}epoch.npz'\n",
    "optim_name = 'dae_{}epoch.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dae = DAE(in_size, mid_size)\n",
    "optimizer = optimizers.Adam()\n",
    "optimizer.setup(dae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: loss = 1.8921667337417603\n",
      "epoch 2: loss = 1.6493866443634033\n",
      "epoch 3: loss = 1.6100345849990845\n",
      "epoch 4: loss = 1.5268738269805908\n",
      "epoch 5: loss = 1.461970329284668\n",
      "epoch 6: loss = 1.451326847076416\n",
      "epoch 7: loss = 1.4093059301376343\n",
      "epoch 8: loss = 1.3982040882110596\n",
      "epoch 9: loss = 1.386332392692566\n",
      "epoch 10: loss = 1.349475383758545\n",
      "save model and optimizer: ./model/dae_512/dae_10epoch.npz, ./model/dae_512/dae_10epoch.npz\n",
      "epoch 11: loss = 1.3274803161621094\n",
      "epoch 12: loss = 1.350356101989746\n",
      "epoch 13: loss = 1.32452392578125\n",
      "epoch 14: loss = 1.2792998552322388\n",
      "epoch 15: loss = 1.3295130729675293\n",
      "epoch 16: loss = 1.306878924369812\n",
      "epoch 17: loss = 1.2838226556777954\n",
      "epoch 18: loss = 1.291928768157959\n",
      "epoch 19: loss = 1.2678831815719604\n",
      "epoch 20: loss = 1.251905083656311\n",
      "save model and optimizer: ./model/dae_512/dae_20epoch.npz, ./model/dae_512/dae_20epoch.npz\n",
      "epoch 21: loss = 1.2486430406570435\n",
      "epoch 22: loss = 1.2438158988952637\n",
      "epoch 23: loss = 1.2417033910751343\n",
      "epoch 24: loss = 1.2398227453231812\n",
      "epoch 25: loss = 1.2411775588989258\n",
      "epoch 26: loss = 1.26339590549469\n",
      "epoch 27: loss = 1.2308552265167236\n",
      "epoch 28: loss = 1.2303062677383423\n",
      "epoch 29: loss = 1.2587873935699463\n",
      "epoch 30: loss = 1.2158852815628052\n",
      "save model and optimizer: ./model/dae_512/dae_30epoch.npz, ./model/dae_512/dae_30epoch.npz\n",
      "epoch 31: loss = 1.2125972509384155\n",
      "epoch 32: loss = 1.2208163738250732\n",
      "epoch 33: loss = 1.2143943309783936\n",
      "epoch 34: loss = 1.2240171432495117\n",
      "epoch 35: loss = 1.2122153043746948\n",
      "epoch 36: loss = 1.2176120281219482\n",
      "epoch 37: loss = 1.20949125289917\n",
      "epoch 38: loss = 1.221203327178955\n",
      "epoch 39: loss = 1.1959164142608643\n",
      "epoch 40: loss = 1.2012892961502075\n",
      "save model and optimizer: ./model/dae_512/dae_40epoch.npz, ./model/dae_512/dae_40epoch.npz\n",
      "epoch 41: loss = 1.2121440172195435\n",
      "epoch 42: loss = 1.2181168794631958\n",
      "epoch 43: loss = 1.1947728395462036\n",
      "epoch 44: loss = 1.1960780620574951\n",
      "epoch 45: loss = 1.2077248096466064\n",
      "epoch 46: loss = 1.196212649345398\n",
      "epoch 47: loss = 1.1932470798492432\n",
      "epoch 48: loss = 1.1838140487670898\n",
      "epoch 49: loss = 1.190476894378662\n",
      "epoch 50: loss = 1.187802791595459\n",
      "save model and optimizer: ./model/dae_512/dae_50epoch.npz, ./model/dae_512/dae_50epoch.npz\n",
      "epoch 51: loss = 1.192578911781311\n",
      "epoch 52: loss = 1.179013967514038\n",
      "epoch 53: loss = 1.1912128925323486\n",
      "epoch 54: loss = 1.186335802078247\n",
      "epoch 55: loss = 1.1861861944198608\n",
      "epoch 56: loss = 1.1833029985427856\n",
      "epoch 57: loss = 1.1824380159378052\n",
      "epoch 58: loss = 1.179001808166504\n",
      "epoch 59: loss = 1.1858197450637817\n",
      "epoch 60: loss = 1.1833620071411133\n",
      "save model and optimizer: ./model/dae_512/dae_60epoch.npz, ./model/dae_512/dae_60epoch.npz\n",
      "epoch 61: loss = 1.1833564043045044\n",
      "epoch 62: loss = 1.173998236656189\n",
      "epoch 63: loss = 1.1625901460647583\n",
      "epoch 64: loss = 1.184709072113037\n",
      "epoch 65: loss = 1.1696351766586304\n",
      "epoch 66: loss = 1.1703786849975586\n",
      "epoch 67: loss = 1.1734811067581177\n",
      "epoch 68: loss = 1.1669172048568726\n",
      "epoch 69: loss = 1.1631135940551758\n",
      "epoch 70: loss = 1.167100429534912\n",
      "save model and optimizer: ./model/dae_512/dae_70epoch.npz, ./model/dae_512/dae_70epoch.npz\n",
      "epoch 71: loss = 1.168135643005371\n",
      "epoch 72: loss = 1.1572374105453491\n",
      "epoch 73: loss = 1.1647919416427612\n",
      "epoch 74: loss = 1.1657054424285889\n",
      "epoch 75: loss = 1.167262077331543\n",
      "epoch 76: loss = 1.1684576272964478\n",
      "epoch 77: loss = 1.1588982343673706\n",
      "epoch 78: loss = 1.1661566495895386\n",
      "epoch 79: loss = 1.164177656173706\n",
      "epoch 80: loss = 1.1628116369247437\n",
      "save model and optimizer: ./model/dae_512/dae_80epoch.npz, ./model/dae_512/dae_80epoch.npz\n",
      "epoch 81: loss = 1.1697953939437866\n",
      "epoch 82: loss = 1.1756181716918945\n",
      "epoch 83: loss = 1.1651195287704468\n",
      "epoch 84: loss = 1.163275122642517\n",
      "epoch 85: loss = 1.1590609550476074\n",
      "epoch 86: loss = 1.1588882207870483\n",
      "epoch 87: loss = 1.167745590209961\n",
      "epoch 88: loss = 1.1512173414230347\n",
      "epoch 89: loss = 1.16305673122406\n",
      "epoch 90: loss = 1.1590964794158936\n",
      "save model and optimizer: ./model/dae_512/dae_90epoch.npz, ./model/dae_512/dae_90epoch.npz\n",
      "epoch 91: loss = 1.1503379344940186\n",
      "epoch 92: loss = 1.1590794324874878\n",
      "epoch 93: loss = 1.1687411069869995\n",
      "epoch 94: loss = 1.1507747173309326\n",
      "epoch 95: loss = 1.1531447172164917\n",
      "epoch 96: loss = 1.1571165323257446\n",
      "epoch 97: loss = 1.1565675735473633\n",
      "epoch 98: loss = 1.1573070287704468\n",
      "epoch 99: loss = 1.1554430723190308\n",
      "epoch 100: loss = 1.1533710956573486\n",
      "save model and optimizer: ./model/dae_512/dae_100epoch.npz, ./model/dae_512/dae_100epoch.npz\n",
      "epoch 101: loss = 1.162290334701538\n",
      "epoch 102: loss = 1.1513808965682983\n",
      "epoch 103: loss = 1.1619759798049927\n",
      "epoch 104: loss = 1.1441550254821777\n",
      "epoch 105: loss = 1.15665602684021\n",
      "epoch 106: loss = 1.1567610502243042\n",
      "epoch 107: loss = 1.1467456817626953\n",
      "epoch 108: loss = 1.154773235321045\n",
      "epoch 109: loss = 1.1508938074111938\n",
      "epoch 110: loss = 1.1496870517730713\n",
      "save model and optimizer: ./model/dae_512/dae_110epoch.npz, ./model/dae_512/dae_110epoch.npz\n",
      "epoch 111: loss = 1.1430268287658691\n",
      "epoch 112: loss = 1.1577754020690918\n",
      "epoch 113: loss = 1.1467666625976562\n",
      "epoch 114: loss = 1.156480073928833\n",
      "epoch 115: loss = 1.1580626964569092\n",
      "epoch 116: loss = 1.1541717052459717\n",
      "epoch 117: loss = 1.1555331945419312\n",
      "epoch 118: loss = 1.1379175186157227\n",
      "epoch 119: loss = 1.1428611278533936\n",
      "epoch 120: loss = 1.1507548093795776\n",
      "save model and optimizer: ./model/dae_512/dae_120epoch.npz, ./model/dae_512/dae_120epoch.npz\n",
      "epoch 121: loss = 1.1501044034957886\n",
      "epoch 122: loss = 1.1544965505599976\n",
      "epoch 123: loss = 1.149975299835205\n",
      "epoch 124: loss = 1.158087134361267\n",
      "epoch 125: loss = 1.1434800624847412\n",
      "epoch 126: loss = 1.1473575830459595\n",
      "epoch 127: loss = 1.1473686695098877\n",
      "epoch 128: loss = 1.1566896438598633\n",
      "epoch 129: loss = 1.1519262790679932\n",
      "epoch 130: loss = 1.144715666770935\n",
      "save model and optimizer: ./model/dae_512/dae_130epoch.npz, ./model/dae_512/dae_130epoch.npz\n",
      "epoch 131: loss = 1.1414659023284912\n",
      "epoch 132: loss = 1.142906904220581\n",
      "epoch 133: loss = 1.1490896940231323\n",
      "epoch 134: loss = 1.1510754823684692\n",
      "epoch 135: loss = 1.1464823484420776\n",
      "epoch 136: loss = 1.145945429801941\n",
      "epoch 137: loss = 1.1387906074523926\n",
      "epoch 138: loss = 1.1431480646133423\n",
      "epoch 139: loss = 1.1437395811080933\n",
      "epoch 140: loss = 1.1422770023345947\n",
      "save model and optimizer: ./model/dae_512/dae_140epoch.npz, ./model/dae_512/dae_140epoch.npz\n",
      "epoch 141: loss = 1.1416740417480469\n",
      "epoch 142: loss = 1.1444085836410522\n",
      "epoch 143: loss = 1.1448619365692139\n",
      "epoch 144: loss = 1.1445434093475342\n",
      "epoch 145: loss = 1.135093331336975\n",
      "epoch 146: loss = 1.1385109424591064\n",
      "epoch 147: loss = 1.1480531692504883\n",
      "epoch 148: loss = 1.140915870666504\n",
      "epoch 149: loss = 1.1341891288757324\n",
      "epoch 150: loss = 1.142041802406311\n",
      "save model and optimizer: ./model/dae_512/dae_150epoch.npz, ./model/dae_512/dae_150epoch.npz\n",
      "epoch 151: loss = 1.1361140012741089\n",
      "epoch 152: loss = 1.1363744735717773\n",
      "epoch 153: loss = 1.1471877098083496\n",
      "epoch 154: loss = 1.1382778882980347\n",
      "epoch 155: loss = 1.1374047994613647\n",
      "epoch 156: loss = 1.1420739889144897\n",
      "epoch 157: loss = 1.1370543241500854\n",
      "epoch 158: loss = 1.1367552280426025\n",
      "epoch 159: loss = 1.14130437374115\n",
      "epoch 160: loss = 1.1308097839355469\n",
      "save model and optimizer: ./model/dae_512/dae_160epoch.npz, ./model/dae_512/dae_160epoch.npz\n",
      "epoch 161: loss = 1.1440712213516235\n",
      "epoch 162: loss = 1.142128348350525\n",
      "epoch 163: loss = 1.1452745199203491\n",
      "epoch 164: loss = 1.1395535469055176\n",
      "epoch 165: loss = 1.1411348581314087\n",
      "epoch 166: loss = 1.1227046251296997\n",
      "epoch 167: loss = 1.1400423049926758\n",
      "epoch 168: loss = 1.1409581899642944\n",
      "epoch 169: loss = 1.1427466869354248\n",
      "epoch 170: loss = 1.142266869544983\n",
      "save model and optimizer: ./model/dae_512/dae_170epoch.npz, ./model/dae_512/dae_170epoch.npz\n",
      "epoch 171: loss = 1.1394537687301636\n",
      "epoch 172: loss = 1.1491148471832275\n",
      "epoch 173: loss = 1.1333091259002686\n",
      "epoch 174: loss = 1.1388806104660034\n",
      "epoch 175: loss = 1.1410313844680786\n",
      "epoch 176: loss = 1.134005069732666\n",
      "epoch 177: loss = 1.1316189765930176\n",
      "epoch 178: loss = 1.1425832509994507\n",
      "epoch 179: loss = 1.1360979080200195\n",
      "epoch 180: loss = 1.140037178993225\n",
      "save model and optimizer: ./model/dae_512/dae_180epoch.npz, ./model/dae_512/dae_180epoch.npz\n",
      "epoch 181: loss = 1.1346862316131592\n",
      "epoch 182: loss = 1.139345645904541\n",
      "epoch 183: loss = 1.1354458332061768\n",
      "epoch 184: loss = 1.1369127035140991\n",
      "epoch 185: loss = 1.1328973770141602\n",
      "epoch 186: loss = 1.1420210599899292\n",
      "epoch 187: loss = 1.1419416666030884\n",
      "epoch 188: loss = 1.1395286321640015\n",
      "epoch 189: loss = 1.13495934009552\n",
      "epoch 190: loss = 1.1369194984436035\n",
      "save model and optimizer: ./model/dae_512/dae_190epoch.npz, ./model/dae_512/dae_190epoch.npz\n",
      "epoch 191: loss = 1.1260513067245483\n",
      "epoch 192: loss = 1.132287859916687\n",
      "epoch 193: loss = 1.1323102712631226\n",
      "epoch 194: loss = 1.138085126876831\n",
      "epoch 195: loss = 1.1434597969055176\n",
      "epoch 196: loss = 1.1391656398773193\n",
      "epoch 197: loss = 1.1294832229614258\n",
      "epoch 198: loss = 1.1330912113189697\n",
      "epoch 199: loss = 1.136756420135498\n",
      "epoch 200: loss = 1.1430212259292603\n",
      "save model and optimizer: ./model/dae_512/dae_200epoch.npz, ./model/dae_512/dae_200epoch.npz\n"
     ]
    }
   ],
   "source": [
    "fp = FloatProgress(min=0, max=(n_feats//batchsize)*n_epochs)\n",
    "display(fp)\n",
    "\n",
    "errors = []\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    shuffle_idx = np.random.permutation(np.arange(n_feats))\n",
    "    for i in range(0, n_feats, batchsize):\n",
    "        batch_idx = shuffle_idx[i:i+batchsize if i+batchsize < n_feats else n_feats]\n",
    "        x_batch = feats[batch_idx]\n",
    "\n",
    "        loss = F.mean_squared_error(dae(x_batch), x_batch)\n",
    "        \n",
    "        dae.cleargrads()\n",
    "        loss.backward()\n",
    "        optimizer.update()\n",
    "        \n",
    "        errors.append(loss.data)\n",
    "        fp.value += 1\n",
    "    \n",
    "    print(\"epoch {}: loss = {}\".format(epoch, loss.data))\n",
    "    \n",
    "    if epoch % save_cycle == 0:\n",
    "        model_fp = save_dir + model_name.format(epoch)\n",
    "        optim_fp = save_dir + optim_name.format(epoch)\n",
    "        serializers.save_npz(model_fp, model)\n",
    "        serializers.save_npz(optim_fp, optimizer)\n",
    "        print('save model and optimizer: {}, {}'.format(model_fp, optim_fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbe603adf28>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbe5fcc9240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evatuate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "138px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "865px",
    "left": "0px",
    "right": "1658px",
    "top": "106px",
    "width": "228px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
